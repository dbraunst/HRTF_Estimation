{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Program Design\n",
    "\n",
    "### Folder Heirarchy\n",
    "\n",
    "```\n",
    "project\n",
    "│   README.md\n",
    "|   markdown-cheatsheet-online.pdf\n",
    "│   HRTF_Estimation.ipynb    \n",
    "|\n",
    "│\n",
    "└───Audio_devtest   #to test file iteration + processing not at-scale\n",
    "│   │   file011.txt\n",
    "|   │   file012.txt\n",
    "│   └───MOS_test\n",
    "│       │   file111.txt\n",
    "│   \n",
    "└───otherFolders\n",
    "    │   file021.txt\n",
    "```\n",
    "\n",
    "### Logical Flow\n",
    "1. Generate Database\n",
    "    1. Generate Annotated Database (ambi_DB) of Ambisonic Representations of MongoDB Soundsources\n",
    "    2. Obtain multiple HRTFs (HRTF_DB), annotated\n",
    "    3. Create Secondary Annotated Database (main_DB) by convolving each in ambi_DB with each in HRTF_DB\n",
    "2. Obtain MOS\n",
    "    1. for each in main_DB\n",
    "        1. Obtain 1 MOS for each in HRTF_DB\n",
    "        2. Compare MOS values \n",
    "            a. search for hyperparameters that yield strong correlations\n",
    "        3. Determine used HRTF for this from main_DB\n",
    "3. Analysis + Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOS Calculation\n",
    "\n",
    "For one processed HRIR$(\\alpha, \\varphi)$ and test set of HRIRs indexed by $(\\theta,\\phi)$\n",
    "\n",
    "Transform each into freq domain (fft)\n",
    "log scale (magnitude dB)\n",
    "\n",
    "Compare each processed HRIR$(\\alpha, \\varphi)$ to every in test set HRIR$(\\theta,\\phi)$ \n",
    "via both Elastic-Net Regression and Jensen-Shannon Distance\n",
    "\n",
    "### Elastic-Net Regression (EN)\n",
    "\n",
    "$\\hat{\\beta} = argmin_\\beta||\\textbf{y}- \\textbf{X}\\beta||^2 + \\delta||\\beta||^2 + \\lambda||\\beta||_1$\n",
    "\n",
    "where: \n",
    "- **y** is the processed signal, \n",
    "- **X** is a matrix where each column is one HRIR from test set HRIR(θ,ϕ)\n",
    "- $\\beta$ is vector of coefficients produced by fitting the model\n",
    "- \"L2 norm\" is defined as $||n||^2 = \\sqrt{(|a|^2 + |b|^2)}$\n",
    "    - where $n = (a, b)$ \n",
    "- δ is the L2 norm shrinkage parameter\n",
    "\n",
    "- \"L1 norm\" is defined as $||n||_1 = |a| + |b|$\n",
    "    - where $n = (a, b)$     \n",
    "- λ is the L1 norm shrinkage parameter\n",
    "    \n",
    "and:\n",
    "- $\\hat{\\beta}$ is the returned vector of coefficients, representing load on each predictor from test HRIR$(\\theta,\\phi)$ to reproduce the input response vector of HRIR$(\\alpha, \\varphi)$.\n",
    "\n",
    "### Jenson-Shannon Distance (JSD)\n",
    "\n",
    "Bounded and symmertical Kullback-Leibler (KL) divergence, measurement of similairty between two distributions. \n",
    "\n",
    "Computes the distance between the processed HRIR and all in test set. Lower values indivate statistically similar distributions, JSD of zero being identical. \n",
    "\n",
    "$JSD(P||T) = \\sqrt{\\frac{1}{2}[KL(P||\\frac{P+T}{2}) + KL(T||\\frac{P+T}{2})]}$\n",
    "\n",
    "where: \n",
    "- $KL(P||T) = \\sum(P(x)\\frac{P(x)}{T(x)})$\n",
    "- $P$ is the processed HRIR response\n",
    "- $T$ is every member of Test HRIR set\n",
    "\n",
    "### E-N distance computation\n",
    "\n",
    "After computing EN distance between processed response signal HRIR$(\\alpha, \\varphi)$ and every member of the test set HRIR$(\\theta,\\phi)$, the returned $\\hat{\\beta}$ coefficients are indeced by \\theta and \\phi. \n",
    "\n",
    "Centroid + StdDev of $\\hat{\\beta}$ coefficients are of interest, as wel as angular distance from computed centroid to intended rendering position. Centroid must be calculated by first shifting distribution to center of image. \n",
    "\n",
    "**MOS-1** is the angular distance of computed centroid -> intended location\n",
    "\n",
    "**MOS-2** is the std deviation of $\\hat{\\beta}$ coefficients as diffuse estimator\n",
    "\n",
    "### JSD computation\n",
    "\n",
    "JSD computed between processed HRIR$(\\alpha, \\varphi)$ and all in computed HRIR$(\\theta,\\phi)$, each value subtracted from 1 and plotted along azimuth + elevation axes. \n",
    "\n",
    "Angular Distance Map (ADM) is computed distance between intended location + every other location. ADM normalized between 0-1. \n",
    "\n",
    "**MOS-3** value at the index of ADM primary return index (highest coefficient value) of the JSD. Smaller MOS-3, more accurate rendering. \n",
    "\n",
    "**MOS-4** sum of all JSD coefficients multiplied by corresponding ADM values. Smaller MOS-4: more compact image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.signal\n",
    "import IPython.display as ipd\n",
    "import sys\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "from sklearn.linear_model import ElasticNet as EN\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as ptch\n",
    "import colorcet as cc\n",
    "import math\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from math import pi as pi\n",
    "\n",
    "import MOS_utilities as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_HRTF(folderpath, filetype=\".wav\", verbose=False):\n",
    "\n",
    "    '''\n",
    "    Reads in an HRTF from file into a 72-by-15 array of stereo impulse responses\n",
    "    \n",
    "    HRTF Ele Positions(12): -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90\n",
    "         Azi Positions(72): 0:355[::5]\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        folderpath (string) : \n",
    "        \n",
    "        \n",
    "        filetype (string) : which type of HRTF file this function will look for, \n",
    "            currently only working with .wav, but planning to extend to .sofa.\n",
    "        \n",
    "        \"WAV\" will search for .wav files, located in subfolder ##K_##bit\n",
    "            filenaming convention is \"azi_#,#_ele_#,#.wav\"\n",
    "            \n",
    "            ##K is Sample Rate\n",
    "            ##bit is bit depth\n",
    "            Commas represent decimals, prepend (-) if negative.\n",
    "            e.g. 15 deg azi, -17.3 deg ele = \"azi_15,0_ele_-17,3.wav\"\n",
    "        \n",
    "        \"sofa\" will search for .sofa files\n",
    "            filenaming convention is \"D#_##K_##bit_###tap_FIR_SOFA.sofa\"\n",
    "            \n",
    "            D# is HRTF subject no. (SADIE II database)\n",
    "            ##K is Sample Rate\n",
    "            ##bit is bit depth\n",
    "            ###tap is FIR length in samples\n",
    "            e.g. \"D2_48K_24bit_256tap_FIR_SOFA.sofa\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "        HRTF_out (np.ndarray, shape(72,1)) : \n",
    "    '''\n",
    "    \n",
    "    HRTF_out = np.ndarray((72, 11, 2, 256))\n",
    "    \n",
    "    if(verbose==True):\n",
    "        print(\"HRTF Shape:\", HRTF_out.shape)\n",
    "\n",
    "    start_az = 0;\n",
    "    start_el = -75;\n",
    "    \n",
    "    # azimuth and elevation increments of 5 and 15 degrees, respectively\n",
    "    az_inc = 5;\n",
    "    el_inc = 15;\n",
    "    \n",
    "    # number of azimuth and elevation measurements\n",
    "    num_azi = 72;\n",
    "    num_ele = 11;\n",
    "    \n",
    "    for az_idx in range(0, num_azi):\n",
    "        for el_idx in range(0, num_ele):\n",
    "            curr_az = start_az + int(az_idx * az_inc);\n",
    "            curr_el = start_el + int(el_idx * el_inc);\n",
    "            \n",
    "            filename = folderpath + \"azi_{:.1f}_ele_{:.1f}\".format(curr_az, curr_el)\\\n",
    "                .replace('.',',') + \".wav\";\n",
    "            \n",
    "            y, sr = librosa.load(filename, sr=None, mono=False);\n",
    "            HRTF_out[az_idx, el_idx] = y;\n",
    "    \n",
    "    return HRTF_out, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_IR_generation(audiofile, IR):\n",
    "    '''\n",
    "    Create a new IR through deconvolving audio signals after digital signal processing\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audiofile : str\n",
    "        processed audio signal to be deconvolced\n",
    "    \n",
    "    IR : str\n",
    "        impulse response used to deconvolve signal\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_IR : np.array, shape (n,2) \n",
    "        new IR representing the digital signal processing \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    processed, fs = librosa.load(audiofile, sr=None, mono=False, duration=11.0)\n",
    "    original, fs = librosa.load(IR, sr=None, mono=False, duration=11.0)\n",
    "    \n",
    "    #take FFT of both signals\n",
    "    processedFFT = np.fft.fft(processed)\n",
    "    originalFFT = np.fft.fft(original)\n",
    "    \n",
    "    #divide the two frequency complex vectors\n",
    "    newFFT = processedFFT / originalFFT\n",
    "    \n",
    "    #bring back to time domain\n",
    "    newIR = np.fft.ifft(newFFT)\n",
    "    \n",
    "    #cast to real numbers\n",
    "    newIR = np.real(newIR)\n",
    "    \n",
    "    return newIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_HRTF(test_HRTF):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    convolved_signal : np.ndarray [shape=(2,n)]\n",
    "    \n",
    "    test_HRTF : np.ndarrray [shape=(72, 11, 2, 256)]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    db-scaled-fft \n",
    "    \n",
    "    db-scaled-fft-of-HRTFs\n",
    "    '''\n",
    "    \n",
    "    dB_HRTF = np.empty((test_HRTF.shape[0],test_HRTF.shape[1],test_HRTF.shape[2],int(test_HRTF.shape[3]/2)));\n",
    "    \n",
    "    for n in range (0, test_HRTF.shape[0]):\n",
    "        for m in range (0, test_HRTF.shape[1]):\n",
    "            dB_HRTF[n,m] = util.dB_weighted_fft(test_HRTF[n,m])\n",
    "        \n",
    "    return dB_HRTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_azimuth(scores, azimuth_idx):\n",
    "    '''\n",
    "    Params:\n",
    "    \n",
    "    Centers data array so input HRTF(alpha, varphi) is centered in array\n",
    "    \n",
    "    -------\n",
    "    scores : np.ndarray, shape=[n, m]\n",
    "    \n",
    "    azimuth : \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    shifted_scores : np.ndarray, [shape=(n, m)]\n",
    "    \n",
    "    xticklabels : np.ndarray, [shape=(n,)]\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    if(azimuth_idx == 0):\n",
    "        ## slice from 0:175 deg, -180:-5 and concatenate\n",
    "        \n",
    "        slice1 = scores[0:int(scores.shape[0]/2)];\n",
    "        slice2 = scores[int(scores.shape[0]/2):scores.shape[0]];\n",
    "        \n",
    "        centered_scores = np.concatenate((slice2, slice1), axis=0);\n",
    "        xticklabels = (np.arange(-180, 181, 20));\n",
    "        \n",
    "    elif(azimuth_idx > 0 and azimuth_idx < 36):\n",
    "        # slice 1 is azi_idx:azi_idx + 35, slice 2 is azi_idx + 35:71, slice 3 is 0:azi_idx\n",
    "        # cat(slice2, slice3, slice1)\n",
    "        \n",
    "        slice1 = scores[azimuth_idx:azimuth_idx + int(scores.shape[0]/2)]\n",
    "        slice2 = scores[azimuth_idx + int(scores.shape[0]/2):scores.shape[0]];\n",
    "        slice3 = scores[0:azimuth_idx];\n",
    "         \n",
    "        centered_scores=np.concatenate((slice2, slice3, slice1), axis=0);\n",
    "        \n",
    "        # ticks + labels follow similar logic, spaced 20 apart and ending +1 beyond array\n",
    "        # azi_idx * 5 = azimuth degrees = offset and leftshift\n",
    "        \n",
    "        \n",
    "        missing_ticks = round(azimuth_idx / 4)    \n",
    "        xlabel_leftbound = int(5 * azimuth_idx) - 180;\n",
    "    \n",
    "        xticklabels =(np.arange(xlabel_leftbound, (191+20*missing_ticks), 20))\n",
    "    \n",
    "    \n",
    "    elif(azimuth_idx > 36 and azimuth_idx <= 71):\n",
    "        # slice 1 is azi_idx:71, slice 2 is 0:(azi_idx-36), slice 3 is azi_idx-35:azi_idx\n",
    "        # cat(slice3, slice 1, slice 2)\n",
    "        \n",
    "        slice1 = scores[azimuth_idx:scores.shape[0]];\n",
    "        slice2 = scores[0:azimuth_idx-int(scores.shape[0]/2)];\n",
    "        slice3 = scores[azimuth_idx-int(scores.shape[0]/2):azimuth_idx];\n",
    "         \n",
    "        centered_scores=np.concatenate((slice3, slice1, slice2), axis=0);\n",
    "        \n",
    "        #number of ticks that will be 'pushed off' by the shift and need to be wrapped around\n",
    "        missing_ticks = int((scores.shape[0] - azimuth_idx) / 4)\n",
    "        np.arange(180-(20*missing_ticks), 191, 20);\n",
    "        \n",
    "        print(centered_scores.shape)\n",
    "        \n",
    "        #ticks beyond 180 = len - idx / 4\n",
    "        xticklabels = np.concatenate((np.arange(180-(20*missing_ticks), 171, 20),\\\n",
    "                                      np.arange(-180, 191-(20*missing_ticks), 20)), axis=0);\n",
    "        \n",
    "    elif(azimuth_idx == 36):\n",
    "         #azimuth == 36, aka 180deg, is alread centered. Do nothing.\n",
    "        centered_scores = scores;\n",
    "        xticklabels = (np.arange(0, 361, 20)); \n",
    "    else:\n",
    "        print(\"Error: please enter an azimuth index value between 0 and \", scores.shape[0]-1);\n",
    "\n",
    "    xticks = (np.arange(0.5, scores.shape[0]+1, 4))\n",
    "    \n",
    "    return centered_scores, xticks, xticklabels;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def process_elastic_net(db_weighted_HRTF, azimuth_index, HRIR=None, normalize=False):\n",
    "    \n",
    "#     (azimuth, elevation, db_weighted_HRTF )\n",
    "    \n",
    "    \n",
    "    # Get 1ch db-weighted-HRIR at chosen azi/ele if not provided\n",
    "#     if (HRIR = None):\n",
    "#         db_HRIR = util.get_HRIR(db_weighted_HRTF, test_azimuth, test_elevation, verbose=False)\n",
    "#         HRIR = db_HRIR[0];\n",
    "#     elif (azimuth == None and elevation == None):\n",
    "#         if (HRIR.nims==2):\n",
    "#             HRIR = HRIR[0];\n",
    "#         else:\n",
    "#             HRIR = HRIR;\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    centered_coeff:\n",
    "    \n",
    "    xticks:\n",
    "    \n",
    "    xticklabels:\n",
    "    \n",
    "    \n",
    "    '''    \n",
    "\n",
    "    # Get Left Channel of HRIR\n",
    "    HRIR = HRIR[0];\n",
    "    \n",
    "# Flatten input HRTF into a neat-o line for ease of EN, also split into mono\n",
    "    flat_HRTF_L, flat_HRTF_R = util.flatten_HRTF_mono(db_weighted_HRTF)\n",
    "\n",
    "# Train Regressor Model\n",
    "    regr3 = ElasticNetCV(cv=5, random_state=0, max_iter=500, normalize=True)\n",
    "    \n",
    "    regr3.fit(flat_HRTF_L.T,  HRIR)\n",
    "\n",
    "    coeff = regr3.coef_\n",
    "    \n",
    "# Once Trained, Generate a score chart based on fitted model of original HRTF dims\n",
    "# currently ignoring stereo\n",
    "\n",
    "    beta_scores = np.empty((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]),\\\n",
    "                           dtype=float);\n",
    "    \n",
    "    coeff = np.empty((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]),\\\n",
    "                           dtype=float);\n",
    "    coeff_iter = 0;\n",
    "    for azi_idx in range(0, db_weighted_HRTF.shape[0]):\n",
    "        for ele_idx in range(0, db_weighted_HRTF.shape[1]):\n",
    "            coeff[azi_idx, ele_idx] = regr3.coef_[coeff_iter];\n",
    "            coeff_iter = coeff_iter + 1;\n",
    "\n",
    "    ## Center and normalize data, generating respective xticks and labels for centered azimuth\n",
    "    centered_coeff, xticks, xticklabels = center_azimuth(coeff, azimuth_idx=azimuth_index);\n",
    "    \n",
    "    if (normalize):\n",
    "        centered_coeff = util.NormalizeData(centered_coeff);\n",
    "        \n",
    "    return centered_coeff, xticks, xticklabels;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jensen-Shannon Distance\n",
    "def process_JSD(db_weighted_HRTF, azimuth_index, HRIR=None, normalize = False):\n",
    "    \n",
    "    HRIR = HRIR[0];\n",
    "    \n",
    "    JSD_map = np.zeros((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]))\n",
    "    \n",
    "    for azi_idx in range(0, db_weighted_HRTF.shape[0]):\n",
    "        for ele_idx in range(0, db_weighted_HRTF.shape[1]):    \n",
    "            JSD_p = util.NormalizeData(HRIR)\n",
    "            JSD_q = util.NormalizeData(test_HRTF[azi_idx, ele_idx, 0])\n",
    "            JSD_map[azi_idx, ele_idx] = 1 - scipy.spatial.distance.jensenshannon(JSD_p, JSD_q);   \n",
    "\n",
    "#     return JSD_map\n",
    "\n",
    "    JSD_centered, xticks, xticklabels = center_azimuth(JSD_map, azimuth_idx=azimuth_index)\n",
    "    \n",
    "    if (normalize)\n",
    "        JSD_centered = util.NormalizeData(JSD_centered);\n",
    "        \n",
    "    return JSD_Centered, xticks, xticklabels;\n",
    "\n",
    "## Angular Distance\n",
    "def angular_distance_map(centered_data, x_index, y_index, normalize=False):\n",
    "    \n",
    "    out = np.zeros_like(centered_data);\n",
    "    \n",
    "    # Using the haversine 'great circle' distance, calculate shortest distance between two points on the unit circle\n",
    "    for azi_idx in range(0, int(centered_data.shape[0])):\n",
    "        for ele_idx in range(0, centered_data.shape[1]):\n",
    "            \n",
    "            # Multipliers are to counterbalance the index spacing to degrees\n",
    "#             out[i,j] = scipy.spatial.distance.euclidean([i, j], [x_index, y_index])\n",
    "\n",
    "            # convert from 2D index to degrees\n",
    "            x = [-180 + (azi_idx*5), -75 + (ele_idx*15)]\n",
    "            y = [-180 + (x_index*5), -75 + (y_index*15)]\n",
    "            \n",
    "            #convert to radians\n",
    "            x_rad = [float(_) * pi / 180.0 for _ in x]\n",
    "            y_rad = [float(_) * pi / 180.0 for _ in y]\n",
    "            \n",
    "            result= haversine_distances([x_rad, y_rad]);\n",
    "            \n",
    "            out[azi_idx,ele_idx] = result[0,1];\n",
    "            \n",
    "    if (normalize)\n",
    "        out = util..NormalizeData(out);\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MOS_1(azimuth_degrees, elevation_degrees, calculated_centroid):\n",
    "# convert from 2D index to degrees\n",
    "    x = [azimuth_degrees, elevation_degrees]\n",
    "    \n",
    "    y = [calculated_centroid[0], calculated_centroid[1]]\n",
    "\n",
    "    #convert to radians\n",
    "    x_rad = [float(_) * pi / 180.0 for _ in x]\n",
    "    y_rad = [float(_) * pi / 180.0 for _ in y]\n",
    "    \n",
    "#     print((haversine_distances([x_rad, y_rad])));\n",
    "    MOS_1 = (haversine_distances([x_rad, y_rad])[0,1])* 180 / pi;\n",
    "    \n",
    "    return MOS_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MOS_2(regression_coefficients, distance_map):\n",
    "    '''\n",
    "    MOS-2 is the weighted standard deviation of EN coefficients, done by taking standard deviation\n",
    "    of ADM values, weighted by their corresponding coefficient values at (theta, phi)\n",
    "    \n",
    "    \n",
    "    Params:    \n",
    "    -------\n",
    "    regression_coefficients : np.ndarray, shape=[n, m]\n",
    "    \n",
    "    distance_map : np.ndarray, shape = [n, m]\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    shifted_scores : np.ndarray, [shape=(n, m)]\n",
    "    \n",
    "    xticklabels : np.ndarray, [shape=(n,)]\n",
    "    '''\n",
    "    \n",
    "    # Create ADM * Coefficient product matrix\n",
    "    ADM_product_mat = np.multiply(coeff_norm, ADM);\n",
    "\n",
    "    weighted_avg = np.average(ADM_product_mat, weights=coeff_norm);\n",
    "    variance = np.average((ADM_product_mat-weighted_avg)**2, weights=coeff_norm);\n",
    "    \n",
    "    MOS_2 = math.sqrt(variance) * 180/pi;\n",
    "\n",
    "    return MOS_2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MOS_3(JensenShannonDist, distance_map):\n",
    "    \n",
    "    \n",
    "    MOS_3_x = np.argmax(JensenShannonDist.T.ravel()) % 72;\n",
    "    MOS_3_y = np.floor(np.argmax(JensenShannonDist.T) / 72);\n",
    "    MOS_3 = distance_map[int(MOS_3_x), int(MOS_3_y)] * 180/pi;\n",
    "    \n",
    "    return MOS_3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MOS_4(JensenShannonDist, distance_map):\n",
    "    \n",
    "    product_matrix = np.multiply(JensenShannonDist, distance_map)\n",
    "    MOS_4 = np.average(product_matrix);\n",
    "    \n",
    "    return MOS_4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART 0: DATA INTIALIZATION and IR generation\n",
    "\n",
    "# Load and Prep Signals\n",
    "dry_sig = librosa.load('Binaural_Chorus_Files/dry_vox_48k_24bit.wav');\n",
    "\n",
    "iteration1 = new_IR_generation('Binaural_Chorus_Files/wet_0.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration2 = new_IR_generation('Binaural_Chorus_Files/wet_45.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration3 = new_IR_generation('Binaural_Chorus_Files/wet_90.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration4 = new_IR_generation('Binaural_Chorus_Files/wet_135.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration5 = new_IR_generation('Binaural_Chorus_Files/wet_180.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration6 = new_IR_generation('Binaural_Chorus_Files/wet_225.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration7 = new_IR_generation('Binaural_Chorus_Files/wet_270.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "iteration8 = new_IR_generation('Binaural_Chorus_Files/wet_315.wav', 'Binaural_Chorus_Files/dry_vox_48k_24bit.wav')\n",
    "\n",
    "# ipd.Audio(iteration1[:,96000:], rate=48000)\n",
    "iteration1.shape\n",
    "\n",
    "proc_HRIR_1\n",
    "print(\"proc_HRIR_shape\", proc_HRIR_1.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### PART 1: PREPROCESSING + GLOBAL VAR PREP\n",
    "\n",
    "## Set your \"Processed HRIR\" azimuth and elevation (in degrees)\n",
    "HRIR=iteration2[:,96000:96256]\n",
    "\n",
    "## from -180 to 179\n",
    "processed_azi = -45;\n",
    "processed_ele = 0;\n",
    "\n",
    "HRTF_path = \"HRTFs/D1_HRIR_WAV/48K_24bit/\";\n",
    "HRTF_filetype_str = \".wav\";\n",
    "\n",
    "## Convert \"Processed Azi\" into array index in order to center data\n",
    "azimuth_idx = int(round(processed_azi / 5)) if (processed_azi >=0 and processed_azi < 360)\\\n",
    "    else int((360 - np.abs(processed_azi) % 360) / 5);\n",
    "\n",
    "## Read in and prep the given HRTF\n",
    "HRTF, sr = read_in_HRTF(HRTF_path, HRTF_filetype_str);\n",
    "test_HRTF = prepare_HRTF(HRTF);\n",
    "# HRIR = util.get_HRIR(test_HRTF, azi=processed_azi, ele=processed_ele);\n",
    "\n",
    "## Turn HRIR into dB-weighted-HRIR (fft, nfft/2, the whole 9 yards)\n",
    "processed_HRIR = util.dB_weighted_fft(HRIR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    ### PART 2: INITIAL CALCULATIONS\n",
    "## Run Elastic Net Regression to get coefficients for MOS-1 and MOS-2, returns centered w/ optional normalization\n",
    "centered_coeff_n, xticks, xticklabels = process_elastic_net(test_HRTF, HRIR=processed_HRIR, normalize=True);\n",
    "\n",
    "## Calculate Jensen-Shannon Distance, return centered w/ optional normalization\n",
    "JSD_centered_n, xticks, xticklabels = process_JSD(test_HRTF, azimuth_idx, HRIR=processed_HRIR, normalize=True);\n",
    "\n",
    "## Calculate centroid and centroid position in degrees\n",
    "centroid = ndimage.measurements.center_of_mass(centered_coeff_n)\n",
    "centroid_deg = tuple(((xticklabels[0] + (centroid[0] * 5)), -75 + (centroid[1] * 15)));\n",
    "\n",
    "## Calculate Angular Distance Map - used for MOS-2, MOS-3, MOS-4\n",
    "ADM = angular_distance_map(centered_coeff_n, 36, 5, normalize=True);\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### PART 3: MOS CALCULATIONS\n",
    "## MOS-1 - angular distance between intended location and calculated centroid\n",
    "MOS_1 = get_MOS_1(azimuth_degrees=processed_azi, elevation_degrees=processed_ele, calculated_centroid=centroid_deg);\n",
    "\n",
    "## MOS-2, weighted standard deviation of EN coefficients, done by taking standard deviation\n",
    "##     of ADM values, weighted by their corresponding coefficient values at (theta, phi)\n",
    "MOS_2 = get_MOS_2(regression_coefficients = centered_coeff_n, distance_map = ADM);\n",
    "\n",
    "## MOS_3 - the distance value of the ADM at the index of highest JSD value\n",
    "MOS_3 = get_MOS_3(JensenShannonDist = JSD_centered_n, distance_map = ADM):\n",
    "\n",
    "## MOS_4 - average of product-wise multiplication of normalized JSD \n",
    "MOS_4 = get_MOS_4(JSD_centered_n, ADM);\n",
    "\n",
    "\n",
    "    ### PART 4: DATA PRINTOUT\n",
    "print(\"Intended Spatialization Location: Azi: {:.1f}°, Ele: {:.1f}°)\".format(processed_azi, processed_ele));\n",
    "print(\"Centroid Indeces: \", centroid);\n",
    "print(\"Calculated centroid: {:.3f}, {:.3f}\".format(centroid_deg[0], centroid_deg[1]));\n",
    "print(\"MOS-1: {:.3f}°, Angular Distance from intended azi,ele to calculated centroid\".format(MOS_1));\n",
    "print(\"MOS-2: {:.3f}°, Std. Deviation of Coefficients over sphere from EN Regression\".format(MOS_2));\n",
    "\n",
    "# print(\"\\nLargest JSD Value Location in Degrees: Azi: {:.1f}°, Ele: {:.1f}°\".format(MOS_3_x, MOS_3_y));\n",
    "print(\"MOS-3: {:.3f}°, Value of Angular Distance Map(ADM) at index of largest JSD value\".format(MOS_3);\n",
    "print(\"MOS-4: {:.3f} , Average of all elements in ADM and JSD product matrix.\".format(MOS_4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting E-N Regression\n",
    "#-------------------------------------------------\n",
    "\n",
    "fig= plt.figure(figsize=(14.4, 2.4))\n",
    "ax0 = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax0.set_title(\"E-N Regression Coefficients\")\n",
    "ax0.set_xlabel(\"Azimuth\")\n",
    "print(\"xt\", xticks, \"\\nxtl\", xticklabels)\n",
    "ax0.set_xticks(xticks)\n",
    "ax0.set_xticklabels(xticklabels)\n",
    "\n",
    "\n",
    "ax0.set_ylabel(\"Elevation\")\n",
    "ax0.set_yticks([0.5, 1.5, 3.5, 5.5, 7.5, 9.5, 10.5])\n",
    "ax0.set_yticklabels([-75, -60, -30, 0, 30, 60, 75])\n",
    "\n",
    "pcm = ax0.pcolor(centered_coeff_n.T, cmap=cc.cm.bgyw)\n",
    "fig.colorbar(pcm)\n",
    "\n",
    "plt.arrow(36, 5, centroid[0]-36, centroid[1]-5, color='red', head_width=0.5, head_length=0.3,head_starts_at_zero=False, overhang=0.01, shape=\"full\")\n",
    "circle = ptch.Ellipse((centroid[0], centroid[1]), MOS_2, MOS_2/3, color='red', fill=False, ls='--', lw=1.5)\n",
    "ax0.add_artist(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting JSD\n",
    "\n",
    "fig = plt.figure(figsize=(14.4, 8.2));\n",
    "ax1 = fig.add_subplot(311)\n",
    "pcm1=plt.pcolor(JSD_norm.T, cmap='jet_r')\n",
    "plt.colorbar(pcm1)\n",
    "ax1.set_title(\"Jensen-Shannon Distance\")\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "pcm2=plt.pcolor(ADM.T, cmap='jet')\n",
    "plt.colorbar(pcm2)\n",
    "ax2.set_title(\"Angular Distance Map\")\n",
    "\n",
    "ax3 = fig.add_subplot(313)\n",
    "pcm3=plt.pcolor(product_mat.T, cmap='jet', vmin=0, vmax=1)\n",
    "plt.colorbar(pcm3)\n",
    "ax3.set_title(\"JSD * ADM Product Matrix\")\n",
    "\n",
    "axs = [ax1, ax2, ax3]\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Azimuth\")\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "\n",
    "    ax.set_ylabel(\"Elevation\")\n",
    "    ax.set_yticks([0.5, 1.5, 3.5, 5.5, 7.5, 9.5, 10.5])\n",
    "    ax.set_yticklabels([-75, -60, -30, 0, 30, 60, 75])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_MOS (audiofile_path, HRTF_path):\n",
    "    \n",
    "    '''Get MOS (np.array) from Audiofile for Specific HRTF\n",
    "    \n",
    "    MOS = {MOS-1, MOS-2, MOS-3, MOS-4}\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audiofile_path : str\n",
    "        file name (*.wav) incl. path of stereo binaural signal\n",
    "        \n",
    "    HRTF_path: str\n",
    "        HRTF folder including (*.wav) HRIRs for convolution\n",
    "        \n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MOS : np.array, shape = (1, 4)\n",
    "        outputs 4 MOS values for input audio file:\n",
    "        \n",
    "        MOS-1: (E-N) Localization Precision of Spectral Magnitude\n",
    "        MOS-2: (E_N) Sptatial Variation / \"Spread\" of Spectral Magnitude\n",
    "        MOS-3: (JSD) Localization Precision of Spectral Magnitude\n",
    "        MOS-4: (JSD) Sptatial Variation / \"Spread\" of Spectral Magnitude\n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration1.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
