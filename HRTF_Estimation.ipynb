{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Program Design\n",
    "\n",
    "### Folder Heirarchy\n",
    "\n",
    "```\n",
    "project\n",
    "│   README.md\n",
    "|   markdown-cheatsheet-online.pdf\n",
    "│   HRTF_Estimation.ipynb    \n",
    "|\n",
    "│\n",
    "└───Audio_devtest   #to test file iteration + processing not at-scale\n",
    "│   │   file011.txt\n",
    "|   │   file012.txt\n",
    "│   └───MOS_test\n",
    "│       │   file111.txt\n",
    "│   \n",
    "└───otherFolders\n",
    "    │   file021.txt\n",
    "```\n",
    "\n",
    "### Logical Flow\n",
    "1. Generate Database\n",
    "    1. Generate Annotated Database (ambi_DB) of Ambisonic Representations of MongoDB Soundsources\n",
    "    2. Obtain multiple HRTFs (HRTF_DB), annotated\n",
    "    3. Create Secondary Annotated Database (main_DB) by convolving each in ambi_DB with each in HRTF_DB\n",
    "2. Obtain MOS\n",
    "    1. for each in main_DB\n",
    "        1. Obtain 1 MOS for each in HRTF_DB\n",
    "        2. Compare MOS values \n",
    "            a. search for hyperparameters that yield strong correlations\n",
    "        3. Determine used HRTF for this from main_DB\n",
    "3. Analysis + Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''obtain_MOS notes / working thoughts:\n",
    "\n",
    "--Before running the system, the input test signals are\n",
    "assumed to be standardized/normalized to unitlength\n",
    "and zero-mean, and the processed signal is\n",
    "assumed to have been centered to zero-mean.\n",
    "    ?? Is this still relevant? Need to test\n",
    "    \n",
    "--EN method requires HRIR, not SOFA\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOS Calculation\n",
    "\n",
    "For one processed HRIR$(\\alpha, \\varphi)$ and test set of HRIRs indexed by $(\\theta,\\phi)$\n",
    "\n",
    "Transform each into freq domain (fft)\n",
    "log scale (magnitude dB)\n",
    "\n",
    "Compare each processed HRIR$(\\alpha, \\varphi)$ to every in test set HRIR$(\\theta,\\phi)$ \n",
    "via both Elastic-Net Regression and Jensen-Shannon Distance\n",
    "\n",
    "### Elastic-Net Regression (EN)\n",
    "\n",
    "$\\hat{\\beta} = argmin_\\beta||\\textbf{y}- \\textbf{X}\\beta||^2 + \\delta||\\beta||^2 + \\lambda||\\beta||_1$\n",
    "\n",
    "where: \n",
    "- **y** is the processed signal, \n",
    "- **X** is a matrix where each column is one HRIR from test set HRIR(θ,ϕ)\n",
    "- $\\beta$ is vector of coefficients produced by fitting the model\n",
    "- \"L2 norm\" is defined as $||n||^2 = \\sqrt{(|a|^2 + |b|^2)}$\n",
    "    - where $n = (a, b)$ \n",
    "- δ is the L2 norm shrinkage parameter\n",
    "\n",
    "- \"L1 norm\" is defined as $||n||_1 = |a| + |b|$\n",
    "    - where $n = (a, b)$     \n",
    "- λ is the L1 norm shrinkage parameter\n",
    "    \n",
    "and:\n",
    "- $\\hat{\\beta}$ is the returned vector of coefficients, representing load on each predictor from test HRIR$(\\theta,\\phi)$ to reproduce the input response vector of HRIR$(\\alpha, \\varphi)$.\n",
    "\n",
    "### Jenson-Shannon Distance (JSD)\n",
    "\n",
    "Bounded and symmertical Kullback-Leibler (KL) divergence, measurement of similairty between two distributions. \n",
    "\n",
    "Computes the distance between the processed HRIR and all in test set. Lower values indivate statistically similar distributions, JSD of zero being identical. \n",
    "\n",
    "$JSD(P||T) = \\sqrt{\\frac{1}{2}[KL(P||\\frac{P+T}{2}) + KL(T||\\frac{P+T}{2})]}$\n",
    "\n",
    "where: \n",
    "- $KL(P||T) = \\sum(P(x)\\frac{P(x)}{T(x)})$\n",
    "- $P$ is the processed HRIR response\n",
    "- $T$ is every member of Test HRIR set\n",
    "\n",
    "### E-N distance computation\n",
    "\n",
    "After computing EN distance between processed response signal HRIR$(\\alpha, \\varphi)$ and every member of the test set HRIR$(\\theta,\\phi)$, the returned $\\hat{\\beta}$ coefficients are indeced by \\theta and \\phi. \n",
    "\n",
    "Centroid + StdDev of $\\hat{\\beta}$ coefficients are of interest, as wel as angular distance from computed centroid to intended rendering position. Centroid must be calculated by first shifting distribution to center of image. \n",
    "\n",
    "**MOS-1** is the angular distance of computed centroid -> intended location\n",
    "\n",
    "**MOS-2** is the std deviation of $\\hat{\\beta}$ coefficients as diffuse estimator\n",
    "\n",
    "### JSD computation\n",
    "\n",
    "JSD computed between processed HRIR$(\\alpha, \\varphi)$ and all in computed HRIR$(\\theta,\\phi)$, each value subtracted from 1 and plotted along azimuth + elevation axes. \n",
    "\n",
    "Angular Distance Map (ADM) is computed distance between intended location + every other location. ADM normalized between 0-1. \n",
    "\n",
    "**MOS-3** value at the index of ADM primary return index (highest coefficient value) of the JSD. Smaller MOS-3, more accurate rendering. \n",
    "\n",
    "**MOS-4** sum of all JSD coefficients multiplied by corresponding ADM values. Smaller MOS-4: more compact image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.signal\n",
    "import IPython.display as ipd\n",
    "import sys\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "from sklearn.linear_model import ElasticNet as EN\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from math import pi as pi\n",
    "\n",
    "import MOS_utilities as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_HRTF(folderpath, filetype=\".wav\", verbose=False):\n",
    "\n",
    "    '''\n",
    "    Reads in an HRTF from file into a 72-by-15 array of stereo impulse responses\n",
    "    \n",
    "    HRTF Ele Positions(12): -75, -60, -45, -30, -15, 0, 15, 30, 45, 60, 75, 90\n",
    "         Azi Positions(72): 0:355[::5]\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        folderpath (string) : \n",
    "        \n",
    "        \n",
    "        filetype (string) : which type of HRTF file this function will look for, \n",
    "            currently only working with .wav, but planning to extend to .sofa.\n",
    "        \n",
    "        \"WAV\" will search for .wav files, located in subfolder ##K_##bit\n",
    "            filenaming convention is \"azi_#,#_ele_#,#.wav\"\n",
    "            \n",
    "            ##K is Sample Rate\n",
    "            ##bit is bit depth\n",
    "            Commas represent decimals, prepend (-) if negative.\n",
    "            e.g. 15 deg azi, -17.3 deg ele = \"azi_15,0_ele_-17,3.wav\"\n",
    "        \n",
    "        \"sofa\" will search for .sofa files\n",
    "            filenaming convention is \"D#_##K_##bit_###tap_FIR_SOFA.sofa\"\n",
    "            \n",
    "            D# is HRTF subject no. (SADIE II database)\n",
    "            ##K is Sample Rate\n",
    "            ##bit is bit depth\n",
    "            ###tap is FIR length in samples\n",
    "            e.g. \"D2_48K_24bit_256tap_FIR_SOFA.sofa\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "        HRTF_out (np.ndarray, shape(72,1)) : \n",
    "    '''\n",
    "    \n",
    "    HRTF_out = np.ndarray((72, 11, 2, 256))\n",
    "    \n",
    "    if(verbose==True):\n",
    "        print(\"HRTF Shape:\", HRTF_out.shape)\n",
    "\n",
    "    start_az = 0;\n",
    "    start_el = -75;\n",
    "    \n",
    "    # azimuth and elevation increments of 5 and 15 degrees, respectively\n",
    "    az_inc = 5;\n",
    "    el_inc = 15;\n",
    "    \n",
    "    # number of azimuth and elevation measurements\n",
    "    num_azi = 72;\n",
    "    num_ele = 11;\n",
    "    \n",
    "    for az_idx in range(0, num_azi):\n",
    "        for el_idx in range(0, num_ele):\n",
    "            curr_az = start_az + int(az_idx * az_inc);\n",
    "            curr_el = start_el + int(el_idx * el_inc);\n",
    "            \n",
    "            filename = folderpath + \"azi_{:.1f}_ele_{:.1f}\".format(curr_az, curr_el)\\\n",
    "                .replace('.',',') + \".wav\";\n",
    "            \n",
    "            y, sr = librosa.load(filename, sr=None, mono=False);\n",
    "            HRTF_out[az_idx, el_idx] = y;\n",
    "    \n",
    "    return HRTF_out, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_IR_generation(audiofile, IR):\n",
    "    '''\n",
    "    Create a new IR through deconvolving audio signals after digital signal processing\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audiofile : str\n",
    "        processed audio signal to be deconvolced\n",
    "    \n",
    "    IR : str\n",
    "        impulse response used to deconvolve signal\n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_IR : np.array, shape (n,2) \n",
    "        new IR representing the digital signal processing \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    y, fs = librosa.load(audiofile, sr=48000)\n",
    "    x, fs = librosa.load(IR, sr=4800)\n",
    "\n",
    "    \n",
    "    new_IR = scipy.signal.deconvolve(y, x)\n",
    "    \n",
    "    return new_IR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_HRTF(test_HRTF):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    convolved_signal : np.ndarray [shape=(2,n)]\n",
    "    \n",
    "    test_HRTF : np.ndarrray [shape=(72, 11, 2, 256)]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    db-scaled-fft \n",
    "    \n",
    "    db-scaled-fft-of-HRTFs\n",
    "    '''\n",
    "    \n",
    "    dB_HRTF = np.empty((test_HRTF.shape[0],test_HRTF.shape[1],test_HRTF.shape[2],int(test_HRTF.shape[3]/2)));\n",
    "    \n",
    "    for n in range (0, test_HRTF.shape[0]):\n",
    "        for m in range (0, test_HRTF.shape[1]):\n",
    "            dB_HRTF[n,m] = util.dB_weighted_fft(test_HRTF[n,m])\n",
    "        \n",
    "    return dB_HRTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def process_elastic_net(azimuth, elevation, db_weighted_HRTF ):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    \n",
    "    '''\n",
    "# # Data should come in prepared\n",
    "#     sig, test_HRTF = prepare_data(G, kemar_HRTF)\n",
    "\n",
    "# Flatten input HRTF into a neat-o line for ease of EN, also split into mono\n",
    "    flat_kemar = util.flatten_HRTF(db_weighted_HRTF)\n",
    "    flat_kemar_L, flat_kemar_R = util.flatten_HRTF_mono(test_HRTF)\n",
    "\n",
    "# Get db-weighted-HRIR at chosen azi/ele \n",
    "    db_HRIR = util.get_HRIR(db_weighted_HRTF, azimuth, elevation)\n",
    "    proc_HRIR_L = db_HRIR[0]\n",
    "\n",
    "# Train Regressor Model\n",
    "    regr3 = ElasticNetCV(cv=5, random_state=0, max_iter=500, normalize=True)\n",
    "\n",
    "    \n",
    "    regr3.fit(flat_kemar_L.T,  proc_HRIR_L)\n",
    "\n",
    "    stuff = regr3.coef_\n",
    "    \n",
    "# Once Trained, Generate a score chart based on fitted model of original HRTF dims\n",
    "# currently ignoring stereo\n",
    "\n",
    "    beta_scores = np.empty((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]),\\\n",
    "                           dtype=float);\n",
    "    \n",
    "    stuff = np.empty((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]),\\\n",
    "                           dtype=float);\n",
    "    coef_iter = 0;\n",
    "    for azi_idx in range(0, db_weighted_HRTF.shape[0]):\n",
    "        for ele_idx in range(0, db_weighted_HRTF.shape[1]):\n",
    "            proc_HRIR = util.get_HRIR(test_HRTF, (0 + (5 * azi_idx)), (-75 + (15 * ele_idx)),\\\n",
    "                                verbose=False)\n",
    "            proc_HRIR_L = proc_HRIR[0]\n",
    "            score = regr3.score(flat_kemar_L.T, proc_HRIR_L)\n",
    "            beta_scores[azi_idx, ele_idx] = score;\n",
    "            \n",
    "            stuff[azi_idx, ele_idx] = regr3.coef_[coef_iter];\n",
    "            coef_iter = coef_iter + 1;\n",
    "            \n",
    "    \n",
    "    return beta_scores, stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Testing E-N REgression 2.0\n",
    "# scores, stuff = process_elastic_net(0, 0, test_HRTF)\n",
    "# stuff.shape\n",
    "\n",
    "# plt.plot(stuff.T)\n",
    "\n",
    "# print(stuff[0:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_scores(scores, azimuth_idx):\n",
    "    '''\n",
    "    Params:\n",
    "    \n",
    "    Centers scores array so input HRTF(alpha, varphi) is centered in array\n",
    "    \n",
    "    -------\n",
    "    scores : np.ndarray, shape=[n, m]\n",
    "    \n",
    "    azimuth : \n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    shifted_scores : np.ndarray, [shape=(n, m)]\n",
    "    \n",
    "    xticklabels : np.ndarray, [shape=(n,)]\n",
    "    '''\n",
    "    \n",
    "    # Need to create 3 sub-arrays: \n",
    "    # 'center' is [36]\n",
    "    # EITHER: \n",
    "    #    if azi_idx == 0 \n",
    "    #       azi = 0, slice 1 is 0:35, slice 2 is 36:71\n",
    "    #       cat(slice2, slice 1)\n",
    "    #    if 0 < azi_idx < 35\n",
    "    #       slice 1 is azi_idx:azi_idx + 35, slice 2 is azi_idx + 35:71, slice 3 is 0:azi_idx\n",
    "    #       cat(slice2, slice3, slice1)\n",
    "    #    if azi_idx == 36\n",
    "    #       it's centered, do nothing\n",
    "    #    if 36 < axi_idx < 71\n",
    "    #       slice 1 is azi_idx:71, slice 2 is 0:(azi_idx-36), slice 3 is azi_idx-35:azi_idx\n",
    "    #       cat(slice3, slice 1, slice 2)\n",
    "    \n",
    "#     centered_scores = np.concat(scores[])\n",
    "    if(azimuth_idx == 0):\n",
    "        ## slice from 0:175 deg, -180:-5 and concatenate\n",
    "        \n",
    "        slice1 = scores[0:int(scores.shape[0]/2)];\n",
    "        slice2 = scores[int(scores.shape[0]/2):scores.shape[0]];\n",
    "        \n",
    "        centered_scores = np.concatenate((slice2, slice1), axis=0);\n",
    "        xticklabels = (np.arange(-180, 181, 20));\n",
    "        \n",
    "    elif(azimuth_idx > 0 and azimuth_idx < 36):\n",
    "        # slice 1 is azi_idx:azi_idx + 35, slice 2 is azi_idx + 35:71, slice 3 is 0:azi_idx\n",
    "        # cat(slice2, slice3, slice1)\n",
    "        \n",
    "        slice1 = scores[azimuth_idx:azimuth_idx + int(scores.shape[0]/2)]\n",
    "        slice2 = scores[azimuth_idx + int(scores.shape[0]/2):scores.shape[0]];\n",
    "        slice3 = scores[0:azimuth_idx];\n",
    "         \n",
    "        centered_scores=np.concatenate((slice2, slice3, slice1), axis=0);\n",
    "        \n",
    "        # ticks + labels follow similar logic, spaced 20 apart and ending +1 beyond array\n",
    "        # azi_idx * 5 = azimuth degrees = offset and leftshift\n",
    "        \n",
    "        \n",
    "        missing_ticks = int(azimuth_idx / 4)    \n",
    "        xlabel_leftbound = int(5 * azimuth_idx) - 180;\n",
    "    \n",
    "        xticklabels =(np.arange(xlabel_leftbound, (191+20*missing_ticks), 20))\n",
    "    \n",
    "    \n",
    "    elif(azimuth_idx > 36 and azimuth_idx <= 71):\n",
    "        # slice 1 is azi_idx:71, slice 2 is 0:(azi_idx-36), slice 3 is azi_idx-35:azi_idx\n",
    "        # cat(slice3, slice 1, slice 2)\n",
    "        \n",
    "        slice1 = scores[azimuth_idx:scores.shape[0]];\n",
    "        slice2 = scores[0:azimuth_idx-int(scores.shape[0]/2)];\n",
    "        slice3 = scores[azimuth_idx-int(scores.shape[0]/2):azimuth_idx];\n",
    "         \n",
    "        centered_scores=np.concatenate((slice3, slice1, slice2), axis=0);\n",
    "        \n",
    "        #number of ticks that will be 'pushed off' by the shift and need to be wrapped around\n",
    "        missing_ticks = int((scores.shape[0] - azimuth_idx) / 4)\n",
    "        np.arange(180-(20*missing_ticks), 191, 20);\n",
    "        \n",
    "        print(centered_scores.shape)\n",
    "        \n",
    "        #ticks beyond 180 = len - idx / 4\n",
    "        xticklabels = np.concatenate((np.arange(180-(20*missing_ticks), 171, 20),\\\n",
    "                                      np.arange(-180, 191-(20*missing_ticks), 20)), axis=0);\n",
    "        \n",
    "    elif(azimuth_idx == 36):\n",
    "         #azimuth == 36, aka 180deg, is alread centered. Do nothing.\n",
    "        centered_scores = scores;\n",
    "        xticklabels = (np.arange(0, 361, 20)); \n",
    "    else:\n",
    "        print(\"Error: please enter an azimuth index value between 0 and \", scores.shape[0]-1);\n",
    "        \n",
    "        \n",
    "    \n",
    "    xticks = (np.arange(0.5, scores.shape[0]+1, 4))\n",
    "    \n",
    "    return centered_scores, xticks, xticklabels;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jensen-Shannon Distance\n",
    "def process_JSD(azimuth, elevation, db_weighted_HRTF, method):\n",
    "    \n",
    "    # Get db-weighted-HRIR at chosen azi/ele \n",
    "    db_HRIR = util.get_HRIR(db_weighted_HRTF, azimuth, elevation)\n",
    "    proc_HRIR_L = db_HRIR[0]\n",
    "    \n",
    "    JSD_map = np.zeros((db_weighted_HRTF.shape[0], db_weighted_HRTF.shape[1]))\n",
    "    \n",
    "#     print(proc_HRIR_L.shape, db_weighted_HRTF[0, 0, 0].shape, JSD_map.shape);\n",
    "    \n",
    "    # This method shifts the entire distribution by setting the lowest to zero\n",
    "    if (method == 'shift'):\n",
    "        for azi_idx in range(0, db_weighted_HRTF.shape[0]):\n",
    "            for ele_idx in range(0, db_weighted_HRTF.shape[1]):    \n",
    "                scalar = np.abs(min(min(proc_HRIR_L), min(test_HRTF[azi_idx, ele_idx, 0])));\n",
    "                JSD_p = proc_HRIR_L + scalar;\n",
    "                JSD_q = test_HRTF[azi_idx, ele_idx, 0] + scalar;\n",
    "                JSD_map[azi_idx, ele_idx] = 1 - scipy.spatial.distance.jensenshannon(JSD_p, JSD_q);\n",
    "                \n",
    "    # This method normalizes the distribution between 0 and 1\n",
    "    elif (method == 'norm'):\n",
    "        for azi_idx in range(0, db_weighted_HRTF.shape[0]):\n",
    "            for ele_idx in range(0, db_weighted_HRTF.shape[1]):    \n",
    "                JSD_p = util.NormalizeData(proc_HRIR_L)\n",
    "                JSD_q = util.NormalizeData(test_HRTF[azi_idx, ele_idx, 0])\n",
    "                JSD_map[azi_idx, ele_idx] = 1 - scipy.spatial.distance.jensenshannon(JSD_p, JSD_q);\n",
    "    \n",
    "    return JSD_map\n",
    "\n",
    "## Angular Distance\n",
    "def angular_distance_map(centered_data, x_index, y_index):\n",
    "    \n",
    "    out = np.zeros_like(centered_data);\n",
    "    \n",
    "    # Using the haversine 'great circle' distance, calculate shortest distance between two points on the unit circle\n",
    "    for azi_idx in range(0, int(centered_data.shape[0])):\n",
    "        for ele_idx in range(0, centered_data.shape[1]):\n",
    "            \n",
    "            # Multipliers are to counterbalance the index spacing to degrees\n",
    "#             out[i,j] = scipy.spatial.distance.euclidean([i, j], [x_index, y_index])\n",
    "\n",
    "            # convert from 2D index to degrees\n",
    "            x = [-180 + (azi_idx*5), -75 + (ele_idx*15)]\n",
    "            y = [-180 + (x_index*5), -75 + (y_index*15)]\n",
    "            \n",
    "            #convert to radians\n",
    "            x_rad = [float(_) * pi / 180.0 for _ in x]\n",
    "            y_rad = [float(_) * pi / 180.0 for _ in y]\n",
    "            \n",
    "            result= haversine_distances([x_rad, y_rad]);\n",
    "            \n",
    "            out[azi_idx,ele_idx] = result[0,1];\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Main\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.vdot(x,x)/x.size)\n",
    "\n",
    "folderpath = \"HRTFs/D1_HRIR_WAV/48K_24bit/\";\n",
    "processed_azi = 0;\n",
    "processed_ele = 0;\n",
    "\n",
    "\n",
    "kemar_HRTF, sr = read_in_HRTF(folderpath, \".wav\")\n",
    "\n",
    "test_HRTF = prepare_HRTF(kemar_HRTF)\n",
    "\n",
    "scores, coeff = process_elastic_net(azimuth=processed_azi, elevation=processed_ele,\\\n",
    "                             db_weighted_HRTF=test_HRTF);\n",
    "\n",
    "print(scores[35:40,7], coeff[35:40,7])\n",
    "\n",
    "\n",
    "azimuth_idx = int(round(processed_azi / 5)) if (processed_azi >=0 and processed_azi < 360)\\\n",
    "    else int((360 - np.abs(processed_azi) % 360) / 5);\n",
    "print(\"azimuth_idx:\", azimuth_idx)\n",
    "\n",
    "plt_scores, xticks, xticklabels = center_scores(coeff, azimuth_idx=azimuth_idx);\n",
    "\n",
    "scores_norm = util.NormalizeData(plt_scores)\n",
    "scores_e = scores_norm**np.e\n",
    "\n",
    "centroid = ndimage.measurements.center_of_mass(scores_norm)\n",
    "stddev = np.std(scores_norm)\n",
    "spdev = scipy.ndimage.variance(scores_norm)\n",
    "_rms = rms(scores_norm)\n",
    "print(\"Centroid:\", centroid, \"\\nStd Dev:\", stddev,\"\\nVariance:\", spdev, \"\\nRoot Mean Squared:\", _rms)\n",
    "\n",
    "\n",
    "# ndimage.measurements.histogram(scores, 0, 1, bins=15)\n",
    "\n",
    "# MOS-3 - angular distance between calculated centroid and intended location\n",
    "\n",
    "# convert from 2D index to degrees\n",
    "x = [processed_azi, processed_ele]\n",
    "y = [-180 + (centroid[0]*5), -75 + (centroid[1]*15)]\n",
    "\n",
    "#convert to radians\n",
    "x_rad = [float(_) * pi / 180.0 for _ in x]\n",
    "y_rad = [float(_) * pi / 180.0 for _ in y]\n",
    "            \n",
    "MOS_1 = (haversine_distances([x_rad, y_rad])[0,1]) * 180 / pi;\n",
    "print(\"MOS-1, Angular Distance: {:.2f}°\".format(MOS_1));\n",
    "# MOS_2 =\n",
    "print(\"MOS-2, Std. Dev of Distances:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(coeff.ravel()), max(coeff.ravel()))\n",
    "\n",
    "coeff_norm = util.NormalizeData(coeff)\n",
    "\n",
    "print(min(coeff_norm.ravel()), max(coeff_norm.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting E-N Regression\n",
    "#-------------------------------------------------\n",
    "# plt_scores, xticks, xticklabels = center_scores(scores_e, 4)\n",
    "\n",
    "fig = plt.figure(figsize=(14.4, 2.4))\n",
    "ax = fig.add_subplot(111 )\n",
    "\n",
    "ax.set_title(\"E-N Regression Coefficients\")\n",
    "ax.set_xlabel(\"Azimuth\")\n",
    "print(\"xt\", xticks, \"\\nxtl\", xticklabels)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels)\n",
    "\n",
    "ax.set_ylabel(\"Elevation\")\n",
    "ax.set_yticks([0.5, 1.5, 3.5, 5.5, 7.5, 9.5, 10.5])\n",
    "ax.set_yticklabels([-75, -60, -30, 0, 30, 60, 75])\n",
    "\n",
    "ax.pcolor(scores_norm.T, cmap=cc.cm.bgyw)\n",
    "\n",
    "# fig.colorbar(im, ax=ax)\n",
    "plt.plot(centroid[0], centroid[1], '.r', label='centroid')\n",
    "circle = plt.Circle((centroid[0], centroid[1]), stddev, color='red', fill=False, ls='--', lw=1.5)\n",
    "ax.add_artist(circle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSD2 = process_JSD(0, 0, test_HRTF, 'norm')\n",
    "JSD2_centered, xticks, xticklabels = center_scores(JSD2, azimuth_idx = 0)\n",
    "JSD2_norm = util.NormalizeData(JSD2_centered)\n",
    "JSD2_e = JSD2_norm ** np.e\n",
    "ADM = angular_distance_map(JSD2_e, 36, 5);\n",
    "\n",
    "product_mat = np.multiply(JSD2_norm, ADM)\n",
    "\n",
    "plt.figure();\n",
    "plt.subplot(311)\n",
    "pcm1=plt.pcolor(JSD2_norm.T, cmap='jet')\n",
    "plt.colorbar(pcm1)\n",
    "\n",
    "plt.subplot(312)\n",
    "pcm2=plt.pcolor(ADM.T, cmap='jet')\n",
    "plt.colorbar(pcm2)\n",
    "\n",
    "plt.subplot(313)\n",
    "pcm3=plt.pcolor(product_mat.T, cmap='jet')\n",
    "plt.colorbar(pcm3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print (product_mat)\n",
    "# print(min(JSD2_centered.ravel()))\n",
    "\n",
    "mos3_x = np.argmax(JSD2_e.T.ravel()) % 72;\n",
    "mos3_y = np.floor(np.argmax(JSD2_e.T) / 72);\n",
    "print(\"MOS3:\", ADM[int(mos3_x), int(mos3_y)])\n",
    "\n",
    "mos4=np.sum(product_mat)\n",
    "print(\"MOS4:\", mos4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_MOS (audiofile_path, HRTF_path):\n",
    "    \n",
    "    '''Get MOS (np.array) from Audiofile for Specific HRTF\n",
    "    \n",
    "    MOS = {MOS-1, MOS-2, MOS-3, MOS-4}\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audiofile_path : str\n",
    "        file name (*.wav) incl. path of stereo binaural signal\n",
    "        \n",
    "    HRTF_path: str\n",
    "        HRTF folder including (*.wav) HRIRs for convolution\n",
    "        \n",
    "        \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MOS : np.array, shape = (1, 4)\n",
    "        outputs 4 MOS values for input audio file:\n",
    "        \n",
    "        MOS-1: (E-N) Localization Precision of Spectral Magnitude\n",
    "        MOS-2: (E_N) Sptatial Variation / \"Spread\" of Spectral Magnitude\n",
    "        MOS-3: (JSD) Localization Precision of Spectral Magnitude\n",
    "        MOS-4: (JSD) Sptatial Variation / \"Spread\" of Spectral Magnitude\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
